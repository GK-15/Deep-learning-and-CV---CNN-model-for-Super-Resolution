# -*- coding: utf-8 -*-
"""xx.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1k2f4btylAr6wVbGl8zRoSOJ4xirVY3wl
"""

#installing pillow to access 1.2.2 version of scipy library
#!pip3 install Pillow
#!pip3 install scipy

#downgrade scipy to use misc library
#!pip install scipy==1.2.2

#libraries imported
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from scipy import misc
from scipy import ndimage
import scipy
import pdb 
import matplotlib.pyplot as plt
import skimage
from skimage.metrics import peak_signal_noise_ratio
import warnings
warnings.filterwarnings("ignore")

def imread(path, is_grayscale=True):
  """
  Read image using its path.
  Default value is gray-scale, and image is read by YCbCr format as the paper said.
  """
  if is_grayscale:
    return misc.imread(path, flatten=True, mode='YCbCr').astype(np.float32)
  else:
    return misc.imread(path, mode='YCbCr').astype(np.float32)


def modcrop(image, scale=3):
  """
  To scale down and up the original image, first thing to do is to have no remainder while scaling operation.
  
  We need to find modulo of height (and width) and scale factor.
  Then, subtract the modulo from height (and width) of original image size.
  There would be no remainder even after scaling operation.
  """
  if len(image.shape) == 3:
    h, w, _ = image.shape
    h = h - np.mod(h, scale)
    w = w - np.mod(w, scale)
    image = image[0:h, 0:w, :]
  else:
    h, w = image.shape
    h = h - np.mod(h, scale)
    w = w - np.mod(w, scale)
    image = image[0:h, 0:w]
  return image

def preprocess(path, scale=3):
  """
  Preprocess single image file 
    (1) Read original image as YCbCr format (and grayscale as default)
    (2) Normalize
    (3) Apply image file with bicubic interpolation
  Args:
    path: file path of desired file
    input_: image applied bicubic interpolation (low-resolution)
    label_: image with original resolution (high-resolution)
  """
  image = imread(path, is_grayscale=True)
  label_ = modcrop(image, scale)

  # Must be normalized
  label_ = label_ / 255.

  input_ = ndimage.interpolation.zoom(label_, (1./scale), prefilter=False)
  input_ = ndimage.interpolation.zoom(input_, (scale/1.), prefilter=False)

  return input_, label_

"""Define the model weights and biases 
"""
## ------ Add your code here: set the weight of three conv layers
# replace 'None' with your hyper parameter numbers
# conv1 layer with biases: 64 filters with size 9 x 9
# conv2 layer with biases and relu: 32 filters with size 1 x 1
# conv3 layer with biases and NO relu: 1 filter with size 5 x 5
class SRCNN(nn.Module):
    def __init__(self):
        super(SRCNN, self).__init__()
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=9, padding=4)
        self.conv2 = nn.Conv2d(in_channels=64, out_channels=32, kernel_size=1, padding=0)
        self.conv3 = nn.Conv2d(in_channels=32, out_channels=1, kernel_size=5, padding=2)

    def forward(self, x):
        out = F.relu(self.conv1(x))
        out = F.relu(self.conv2(out))
        out = self.conv3(out)
        return out

"""Load the pre-trained model file
"""
model = SRCNN()
model.load_state_dict(torch.load('/content/model.pth'))
model.eval()

"""Read the test image
"""
LR_image, HR_image = preprocess('/content/butterfly_GT.bmp')
#transform the input to 4-D tensor
input_ = np.expand_dims(np.expand_dims(LR_image, axis=0), axis=0)
input_ = torch.from_numpy(input_)

"""Run the model and get the SR image
"""
with torch.no_grad():
    output_ = model(input_)

#Convert tensor to array
SR_image = output_.numpy()
SR_image = np.reshape(SR_image, (255, 255))

##------ Add your code here: save the LR and SR images and compute the psnr
# hints: use the 'scipy.misc.imsave()'  and ' skimage.metrics.peak_signal_noise_ratio()'

highres = scipy.misc.imsave('high_resolution.jpg',HR_image)

lowres = scipy.misc.imsave('low_resolution.jpg',LR_image)

supres = scipy.misc.imsave('super_resolution.jpg',SR_image)

#plot low resolution image
print(LR_image)
#pdb.set_trace()
print("Low resolution image")
plt.imshow(LR_image,cmap='Greys_r')
plt.show()

#plot high resolution image
print(HR_image)
#pdb.set_trace()
print("High resolution image")
plt.imshow(HR_image,cmap='Greys_r')
plt.show()

#plot super resolution image
print(SR_image)
print("super resolution image")
plt.imshow(SR_image,cmap='Greys_r')
plt.show()

#getting a groundtruth image
groundtruth_image = modcrop(HR_image, 5)
print(groundtruth_image.shape)
#save the groundtruth image
grimg = scipy.misc.imsave('groundtruth_image.jpg',groundtruth_image)
#plot groundtruth image
print("Groundtruth image")
plt.imshow(groundtruth_image,cmap='Greys_r')
plt.show()

#PSNR of high resolution image with bicubic interpolation
print("PSNR of high resolution image with BI")
PSNR1 = peak_signal_noise_ratio(HR_image,LR_image)
print(PSNR1)

#PSNR of high resolution image with SRCNN
print("PSNR of high resolution image with SRCNN")
PSNR2 = peak_signal_noise_ratio(HR_image,SR_image)
print(PSNR2)
